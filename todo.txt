Checklist of my experiments on this dataset's objective. Model tests / methods are grouped by Python library tools to simplify my thoughts or prohibit me from spazzing out.

[x] SkLearn Tools: Construct Model Chains of Classifiers: More focus on probabilistic models and sentence embeddings
    [x] Topic Classification: creates topic labels based on the training data samples and using these as prediction tools
    [x] Language Classification: given that the embeddings were extracted from a pre-trained model on multi-lingual datasets, the classification model for this section is good
    [x] Which llm produce the sequence: Given that the topic classifiers returned poor results, another useful feature is to leverage the llm that is the frequent winner. The frequent winner includes gpt-o1 and llama.
        [x] Multilabel classifier: Extremely poor results
        [ ] Perhaps their rankings could be leverage upon their scoring points. Model this problem as a Ranking Scores classifier instead of multi-label classification problem
    [x] Final prediction score: Preferred vs not preferred

[ ] Sentence Transformers: More focus on the sentence embeddings
    [x] Contrastive Learning / Triple Loss function method (maximising distance of unwanted pairs and minimizing the wanted pairs of texts)
    [...] Teacher Student Model - requires more compute. This method might not work and is a costly trial.

[ ] PyTorch Manual build: More focus on model build
    [x] Data Preparation tools for custom build networks - a refresher of pytorch basics
    [x] Using RNN as an example encoder. I did not expect this to yield good results as the texts were previously encoded and mean pooled hence, the embeddings wouldn't present features useful for predictions but was good refresher anyways